# ModelAPI 使用文档

## 简介

`ModelAPI` 类提供了一个统一的接口，用于与不同的语言模型进行交互，包括 GLM-4、GPT4o 和 Qwen 家族的模型。它简化了向这些模型发送请求和获取响应的过程。通过新增的功能，`ModelAPI` 现在还支持结合文件内容的模型交互，提供更灵活的分析能力。

本手册将详细说明如何使用 `ModelAPI` 类，包括所有参数的类型和作用，以及如何根据不同的需求选择文本分析或结合文件的分析方式。

## 参数概览

所有需要的参数都通过一个字典对象传递，包括类的初始化参数和方法的调用参数。以下是所有可用参数的列表。

### 参数列表

| 参数名        | 类型    | 作用                                                                                                                                           |
|---------------|---------|------------------------------------------------------------------------------------------------------------------------------------------------|
| model_family  | `str`   | 模型家族名称，可选值为 `"glm-4"`、`"gpt4o"` 或以 `"qwen"` 开头的模型家族名称。                                                                  |
| api_key       | `str`   | 用于验证身份的 API 密钥。                                                                                                                       |
| base_url      | `str`   | *(可选)* API 端点的基 URL。如果未提供，将根据 `model_family` 自动设置。                                                                         |
| prompt        | `str`   | 用户的提示文本，用于初始化对话。                                                                                                               |
| text          | `str`   | *(可选)* 待分析的文本内容，可与 `prompt` 结合使用。                                                                                           |
| model_name    | `str`   | 要使用的具体模型名称，例如 `"glm-4-flash"` 或 `"qwen-long"`。                                                                                  |
| max_tokens    | `int`   | *(可选)* 模型生成的最大 token 数，默认为 `1000`。                                                                                              |
| n             | `int`   | *(可选)* 要返回的响应数量，默认为 `1`。                                                                                                       |
| temperature   | `float` | *(可选)* 控制生成的随机性，值越高生成的内容越随机，默认为 `0.7`。                                                                            |
| use_files     | `bool`  | *(可选)* 是否在分析过程中使用文件，默认为 `False`。                                                                                           |
| files         | `list`  | *(可选)* 文件路径的列表，用于上传并在分析过程中结合使用。只有当 `use_files` 为 `True` 时该参数才有效。                                       |

## 方法说明

### 初始化 `ModelAPI`

可以通过传递包含上述参数的字典来创建 `ModelAPI` 实例。例如：

```python
params = {
    "model_family": "qwen",
    "api_key": "your_api_key_here",
    "prompt": "你的提示文本",
    "model_name": "qwen-long",
    "max_tokens": 1000,
    "n": 1,
    "temperature": 0.7,
    "use_files": False  # 如果不使用文件分析，可以省略此参数
}

model_api = ModelAPI(params)
```

### 调用 `analyze` 方法

`analyze` 方法根据 `use_files` 参数的值来选择合适的分析方式：
- 如果 `use_files` 为 `False`，将调用文本分析方法，仅对文本内容进行分析。
- 如果 `use_files` 为 `True`，并且提供了 `files` 参数，则会先上传这些文件，再结合文件内容进行分析。

#### 示例：仅文本分析

```python
result = model_api.analyze()
print("Result:", result)
```

#### 示例：结合文件分析

```python
params = {
    "model_family": "qwen",
    "api_key": "your_api_key_here",
    "prompt": "你的提示文本",
    "model_name": "qwen-long",
    "max_tokens": 1000,
    "n": 1,
    "temperature": 0.7,
    "use_files": True,
    "files": ["file1.txt", "file2.txt",...] # 可以传入更多的文件
}

model_api = ModelAPI(params)
result = model_api.analyze()
print("Result:", result)
```

## 常见问题

### 1. 如何选择是否使用文件分析？
如果你的分析场景中涉及到额外的上下文信息（例如大量的参考文档），可以将 `use_files` 设置为 `True`，并通过 `files` 参数提供这些文件。否则，直接进行文本分析即可。

### 2. 上传的文件需要具备什么条件？
上传的文件需要是可读的文本文件，且文件路径需要是本地可访问的路径。文件在分析过程中会被上传至模型服务器以便结合内容进行分析。

## 结论

`ModelAPI` 类通过灵活的参数配置，允许用户选择适合当前需求的模型分析方式。不论是仅使用文本，还是结合上传的文档，`ModelAPI` 都能提供便捷的接口来实现复杂的交互和分析任务。

